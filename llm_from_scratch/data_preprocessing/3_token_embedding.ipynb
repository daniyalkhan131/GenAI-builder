{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33de2bec",
   "metadata": {},
   "source": [
    "### Token Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab5dea",
   "metadata": {},
   "source": [
    "#### Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435343bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors=model\n",
    "\n",
    "# Let us look how the vector embedding of a word looks like\n",
    "print(word_vectors['computer'])  # Example: Accessing the vector for the word 'computer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad21e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_vectors['cat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using most_similar\n",
    "print(word_vectors.most_similar(positive=['king', 'woman'], negative=['man'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of calculating similarity\n",
    "print(word_vectors.similarity('woman', 'man'))\n",
    "print(word_vectors.similarity('king', 'queen'))\n",
    "print(word_vectors.similarity('uncle', 'aunt'))\n",
    "print(word_vectors.similarity('boy', 'girl'))\n",
    "print(word_vectors.similarity('nephew', 'niece'))\n",
    "print(word_vectors.similarity('paper', 'water'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdafa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_vectors.most_similar(\"tower\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ae50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Words to compare\n",
    "word1 = 'man'\n",
    "word2 = 'woman'\n",
    "\n",
    "word3 = 'semiconductor'\n",
    "word4 = 'earthworm'\n",
    "\n",
    "word5 = 'nephew'\n",
    "word6 = 'niece'\n",
    "\n",
    "# Calculate the vector difference\n",
    "vector_difference1 = model[word1] - model[word2]\n",
    "vector_difference2 = model[word3] - model[word4]\n",
    "vector_difference3 = model[word5] - model[word6]\n",
    "\n",
    "# Calculate the magnitude of the vector difference\n",
    "magnitude_of_difference1 = np.linalg.norm(vector_difference1)\n",
    "magnitude_of_difference2 = np.linalg.norm(vector_difference2)\n",
    "magnitude_of_difference3 = np.linalg.norm(vector_difference3)\n",
    "\n",
    "\n",
    "# Print the magnitude of the difference\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word1, word2, magnitude_of_difference1))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word3, word4, magnitude_of_difference2))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word5, word6, magnitude_of_difference3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74018797",
   "metadata": {},
   "source": [
    "#### token embedding in llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b651911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3be9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6e5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f1a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e637324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bd93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afbea6",
   "metadata": {},
   "source": [
    "### POSITIONAL EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0fc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a71fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/daniyalkhan/Documents/AI/DL/genAI-builders/llm_from_scratch')\n",
    "from utils import create_dataloader_v1\n",
    "with open(\"/Users/daniyalkhan/Documents/AI/DL/genAI-builders/llm_from_scratch/data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f395256",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb4a33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d92a939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5adbaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "057accf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc2d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5aefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
